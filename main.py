import os
import openai
import fitz  # PyMuPDF (PDFì—ì„œ í”„ë¡¬í”„íŠ¸ ì½ê¸°)
import requests
from fastapi import FastAPI, HTTPException
from config import OPENAI_API_KEY, BACKEND_SERVER  # ì„¤ì • íŒŒì¼ì—ì„œ ê°’ ê°€ì ¸ì˜¤ê¸°

# OpenAI API í‚¤ ì„¤ì •
openai.api_key = OPENAI_API_KEY

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI()

# PDFì—ì„œ í”„ë¡¬í”„íŠ¸ ì½ê¸° í•¨ìˆ˜
def read_prompt_from_pdf(pdf_path: str) -> str:
    try:
        doc = fitz.open(pdf_path)
        text = ""
        for page in doc:
            text += page.get_text("text") + "\n"
        return text.strip()
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"PDF ì½ê¸° ì˜¤ë¥˜: {str(e)}")

# LLM ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def generate_response(latest_posts, new_post, prompt: str) -> str:
    messages = [
        {"role": "system", "content": prompt},
        {"role": "user", "content": f"ìµœê·¼ ì‘ì„±ëœ ê¸€ë“¤: {latest_posts}"},
        {"role": "user", "content": f"ìƒˆë¡­ê²Œ ì‘ì„±í•˜ë ¤ëŠ” ì œëª©: {new_post['title']}, ë©”ëª¨: {new_post['memo']}"}
    ]
    client = openai.OpenAI()
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages
    )

    return response.choices[0].message.content

# AI ì„œë²„ ì—”ë“œí¬ì¸íŠ¸: OpenAIë¥¼ í˜¸ì¶œí•˜ì—¬ ìƒˆ ê¸€ ì‘ë‹µ ìƒì„±
@app.post("/{userId}/articles")
async def generate_text(userId: str):
    pdf_path = "prompt.pdf"
    if not os.path.exists(pdf_path):
        raise HTTPException(status_code=404, detail="í”„ë¡¬í”„íŠ¸ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")

    # PDFì—ì„œ í”„ë¡¬í”„íŠ¸ ì½ê¸°
    prompt_text = read_prompt_from_pdf(pdf_path)

    # ë°±ì—”ë“œì—ì„œ ìµœì‹  ë¸”ë¡œê·¸ ê¸€ ê°€ì ¸ì˜¤ê¸° (POST ë°©ì‹)
    latest_posts_url = f"{BACKEND_SERVER}/{userId}/users/articles"
    latest_posts_response = requests.post(latest_posts_url, json={"userId": userId})

    if latest_posts_response.status_code != 200:
        raise HTTPException(status_code=500, detail="ìµœì‹  ë¸”ë¡œê·¸ ê¸€ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ")

    latest_posts = latest_posts_response.json()

    # ë°±ì—”ë“œì—ì„œ ìƒˆ ê¸€ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (POST ë°©ì‹)
    new_post_url = f"{BACKEND_SERVER}/{userId}/articles"
    new_post_response = requests.post(new_post_url, json={"userId": userId})

    if new_post_response.status_code != 200:
        raise HTTPException(status_code=500, detail="ìƒˆ ê¸€ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ")

    new_post = new_post_response.json()

    # ğŸ”¹ ë°ì´í„°ê°€ ëª¨ë‘ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸ (í•˜ë‚˜ë¼ë„ ì—†ìœ¼ë©´ ì˜¤ë¥˜ ë°˜í™˜)
    if not latest_posts or not new_post or "title" not in new_post or "memo" not in new_post:
        raise HTTPException(status_code=400, detail="í•„ìˆ˜ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # OpenAIì— ìš”ì²­í•˜ì—¬ ì‘ë‹µ ìƒì„±
    response_text = generate_response(latest_posts, new_post, prompt_text)

    # ì œëª©ê³¼ ìƒì„±ëœ ì‘ë‹µì„ ë°±ì—”ë“œì— ì €ì¥ 
    save_response_url = f"{BACKEND_SERVER}/{userId}/articles"
    save_payload = {
        "title": new_post["title"],
        "content": response_text
    }
    save_response = requests.post(save_response_url, json=save_payload)

    if save_response.status_code != 200:
        raise HTTPException(status_code=500, detail="ìƒì„±ëœ ì‘ë‹µì„ ì €ì¥í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ")

    return {
        "title": new_post["title"],
        "content": response_text
    }


# í„°ë¯¸ë„ ì‹¤í–‰ -> FastAPI ì„œë²„ ì‹¤í–‰
# uvicorn main:app --host 0.0.0.0 --port 8000
# ê´€ë¦¬ì ëª¨ë“œë¡œ ì‹¤í–‰
# fastapi dev main.py